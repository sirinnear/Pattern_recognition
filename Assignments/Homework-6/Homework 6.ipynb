{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1)\n",
    "Since a lot of your guys seem a bit rusty at calculus.\n",
    "Refer to numerator convention from wiki https://en.wikipedia.org/wiki/Matrix_calculus\n",
    "Calculus Basics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) \n",
    "Let \n",
    "$$\\theta(s) = \\frac{1}{1+\\exp(-s)}$$\n",
    "Show that \n",
    "$$\n",
    "\\frac{\\partial}{\\partial x} \\theta(x) = \\theta(x)(1-\\theta(x))\n",
    "$$\n",
    "\n",
    "Blame P' Ohm if the sign is wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial x} \\theta(x) = \\frac{exp(-x)}{(1+exp(-x))^2} = \\frac{exp(-x)}{(1+exp(-x))^2} = \\frac{1-1 + exp(-x)}{(1+exp(-x))^2} = \\frac{1 + exp(-x)}{(1+exp(-x))^2} - \\frac{1}{(1+exp(-x))^2} = \\frac{1}{1+exp(-x)}  - \\frac{1}{(1+exp(-x))^2} = \\theta (x) - (\\theta (x))^2 \\\\\n",
    "\\frac{\\partial}{\\partial x} \\theta(x) = \\theta (x)(1 - \\theta (x)) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2) \n",
    "\n",
    "Find (This is the logistic cost function)\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial z} y\\ln(\\theta(z)) + (1-y) \\ln(1-\\theta(z)) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial z} y\\ln(\\theta(z)) + \\frac{\\partial}{\\partial z}(1-y) \\ln(1-\\theta(z)) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial z} y\\ln(\\theta(z)) = y*\\theta (z)(1 - \\theta(z))*\\frac{1}{\\theta(z)} = y(1 - \\theta(z)) = y - y\\theta(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial z}(1-y) \\ln(1-\\theta(z)) = (1-y)*(-\\theta(z))(1 - \\theta(z))*\\frac{1}{1-\\theta(z)} = (1-y)*(-\\theta(z)) = -\\theta(z) + y\\theta(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial z} y\\ln(\\theta(z)) + \\frac{\\partial}{\\partial z}(1-y) \\ln(1-\\theta(z)) = y - y\\theta(z) -\\theta(z) + y\\theta(z) = y - \\theta(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3)\n",
    "\n",
    "Let $w$ be $n_w \\times 1$ matrix. Find\n",
    "\n",
    "$$\\frac{\\partial}{\\partial{w}}w^T$$\n",
    "\n",
    "The most straightforward way is to write out $w^T$ as component and use the definition of vector derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w = \n",
    "\\begin{bmatrix}\n",
    "w_1\\\\\n",
    "w_2 \\\\\n",
    "\\vdots \\\\\n",
    "w_n\n",
    "\\end{bmatrix} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w^T = w_1 + w_2 + \\dots + w_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial w} w^T = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial w}{\\partial w_1} & \\frac{\\partial w}{\\partial w^2} & \\dots & \\frac{\\partial w}{\\partial w_n}\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & \\dots & 0 \\\\\n",
    "0 & 1 & \\dots & 0 \\\\\n",
    "\\vdots & & \\ddots & \\\\\n",
    "0 & 0 & \\dots & 1\n",
    "\\end{bmatrix} = I_{n_w \\times n_w}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4)\n",
    "\n",
    "Let $w$ be $n_x \\times 1$ matrix, $x$ be $n_x \\times 1 $ matrix and $b$ be a number\n",
    "Find (be careful with transpose)\n",
    "\n",
    "$$\n",
    "    \\frac{\\partial}{\\partial \\vec{w}} w^Tx + b\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w = \n",
    "\\begin{bmatrix}\n",
    "w_1 \\\\ w_2 \\\\ \\vdots \\\\ w_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "x = \n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "w^Tx = \n",
    "\\begin{bmatrix}\n",
    "w_1 & w_2 & \\dots & w_n\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n\n",
    "\\end{bmatrix} = \n",
    "w_1x_1 + w_2x_2 + \\dots + w_nx_n = f\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\frac{\\partial}{\\partial \\vec{w}} w^Tx = \\frac{\\partial}{\\partial \\vec{w}} f = \n",
    "    \\frac{\\partial f}{\\partial w_1} + \\frac{\\partial f}{\\partial w_2} + \\dots + \\frac{\\partial f}{\\partial w_n} = \n",
    "    x_1 + x_2 + \\dots + x_n = x^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\frac{\\partial}{\\partial \\vec{w}} w^Tx + b = x^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5)\n",
    "\n",
    "Find $$\n",
    "\\frac{\\partial}{\\partial \\vec{w}} y\\ln(\\theta(z)) + (1-y) \\ln(1-\\theta(z)) \n",
    "$$\n",
    "\n",
    "where $$\n",
    "    z = w^Tx + b\n",
    "$$\n",
    "\n",
    "Note: Make a little proof to convince your self that this is the log likelihood cost function with 0,1 class(instead of positive negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial \\vec{w}} y\\ln(\\theta(w^Tx + b)) + \\frac{\\partial}{\\partial \\vec{w}}(1-y) \\ln(1-\\theta(w^Tx + b))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial \\vec{w}} y\\ln(\\theta(z)) = y*(x^T)* \\theta (z)(1 - \\theta(z))*\\frac{1}{\\theta(z)} = y*(x^T)*(1 - \\theta(z)) = x^Ty*(1 - \\theta(z)) = x^Ty - x^Ty\\theta(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial \\vec{w}}(1-y) \\ln(1-\\theta(z)) = (1-y)*(x^T)*(-\\theta(z)(1-\\theta(z)*\\frac{1}{1-\\theta(z)} = (1-y)*(x^T)*(-\\theta(z) = (x^T - x^Ty)(-\\theta(z) = -x^T\\theta(z) + x^Ty\\theta(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial \\vec{w}} y\\ln(\\theta(z)) + \\frac{\\partial}{\\partial \\vec{w}}(1-y) \\ln(1-\\theta(z)) = x^Ty - x^Ty\\theta(z) -x^T\\theta(z) + x^Ty\\theta(z) = x^Ty - x^T\\theta(z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6)\n",
    "\n",
    "Using vector derivative we learned in class to day to show that \n",
    "Minimization of (least square cost)\n",
    "$$\n",
    "f(\\vec{w}) =  ||X^T w - y||_2 = (X^T w - y)^2 = (X^T w - y)^T(X^T w - y)\n",
    "$$ \n",
    "leads to exactly the normal equation we had in Numerical Methods.\n",
    "\n",
    "$$\n",
    "    \\vec{w}^* = (XX^T)^{-1}Xy\n",
    "$$\n",
    "\n",
    "Where $X$ is an $n \\times M$ matrix, $w$ is an $n\\times 1$ matrix and $y$ is $M \\times 1$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial \\vec{w}} f(\\vec{w}) = \\frac{\\partial}{\\partial \\vec{w}} (X^Tw - y)^T(X^Tw-y) = \\frac{\\partial}{\\partial \\vec{w}} (Xw^T - y^T)(X^Tw - y) = \\frac{\\partial}{\\partial \\vec{w}} (XX^Tww^T - Xw^Ty - X^Twy^T + yy^T)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since \n",
    "$\n",
    "Xw^Ty = X^Twy^T \\Rightarrow Xw^Ty + X^Twy^T = 2Xw^Ty\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial \\vec{w}} (XX^Tww^T - 2Xw^Ty + yy^T) = \\frac{\\partial}{\\partial \\vec{w}} (w^TXw)(X^T) - \\frac{\\partial}{\\partial \\vec{w}} (w^Ty)(2X) + \\frac{\\partial}{\\partial \\vec{w}} yy^T = 2XX^Tw - 2Xy = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "2XX^T \\vec{w} - 2Xy = 0 \\Rightarrow 2XX^T \\vec{w} = 2Xy \\Rightarrow 2\\vec{w}^* = (XX^T)^{-1}2Xy \\Rightarrow \\vec{w}^* = (XX^T)^{-1}Xy\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7) \n",
    "\n",
    "Show that optimization of\n",
    "\n",
    "$$\n",
    "    f(x) = x^T A x + b^T x + c\n",
    "$$\n",
    "\n",
    "subject to $$x^Tx = 1$$\n",
    "\n",
    "Leads to an eigen value problem\n",
    "\n",
    "$$\\Sigma x = \\lambda x$$\n",
    "\n",
    "find $\\Sigma$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial x} x^TAx + b^Tx + c = (A+A^T)x + b^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial}{\\partial x} x^Tx = x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "(A + A^T)x + b^T = \\lambda x \\Rightarrow \\Rightarrow (A + A^T + \\frac{b^T}{x})x = \\lambda x\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sum = A + A^T + \\frac{b^T}{x}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2) \n",
    "\n",
    "Given USPS Data we used in class\n",
    "\n",
    "1.1) Use PCA to reduce the images to 20 features and classify it on test data. Report the error on test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = loadmat('usps_resampled/usps_resampled.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 4649)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = D['train_patterns']\n",
    "print(images.shape)\n",
    "def show(img):\n",
    "    im = img.reshape(16,16) #you can try print it\n",
    "    plt.imshow(im, interpolation='none', cmap=cm.Greys)\n",
    "show(images[:,0])\n",
    "\n",
    "labels = np.argmax(D['train_labels'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('pca', PCA(20)),\n",
    "    ('logistic', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('pca',\n",
       "                 PCA(copy=True, iterated_power='auto', n_components=20,\n",
       "                     random_state=None, svd_solver='auto', tol=0.0,\n",
       "                     whiten=False)),\n",
       "                ('logistic',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(images.T, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipe.predict(images.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9346095934609594\n",
      "4649\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(labels==result)/ len(result))\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = D['test_patterns']\n",
    "test_labels = np.argmax(D['test_labels'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9244998924499892\n",
      "4649\n"
     ]
    }
   ],
   "source": [
    "test_result = pipe.predict(test_images.T)\n",
    "print(np.sum(test_labels==test_result)/ len(test_result))\n",
    "print(len(test_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2) Plot classifier performance(y axis)(%correct) against the number of feature kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "174px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
